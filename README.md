# Zero to AI

The lessons in this course are around Neural Networks and the Transformer architecture that is at the root of the current AI revolution.

I put this course together to both learn about and potentially educate others that are on the journey to understand the current state of AI.

My goal was to try and explain it to myself in a way that a motivated High School student could follow along.

## Sources

The material here is sourced from:
- [Andrej Karpathy - NN-Zero-To-Hero](https://github.com/karpathy/nn-zero-to-hero)
- [Vik Parchuri - Zero_To_GPT](https://github.com/VikParuchuri/zero_to_gpt/tree/master?tab=readme-ov-file)
- [Tivadar Danka - Mathematics of Machine Learning](https://tivadardanka.com/mathematics-of-machine-learning-preview)
- [CS-231 Stanford University](https://cs231n.github.io/)

## Course Outline

1. **Math Fundamentals**: Lessons on basics of linear algebra and calculus
   - [Terminology and Notation](/notes/term-not.ipynb)
   - [Data Structures - Scalars, Vectors, Matrices](/notes/data-structs.ipynb)
   - [Introduction to Functions, Derivatives and Gradients](/notes/func-der-grad.ipynb)
   - [Derivative of a function of a single variable](/notes/derivative-single-var.ipynb)
   - [Derivative of a function of multiple variables](/notes/derivative-multiple-var.ipynb)

2. **Machine Learning**
   - [What is Machine Learning and types](/notes/what-is-ml.ipynb)
   - [Why and how does an algorithm "learn"](/notes/why-algo-learns.ipynb)
   - [Fundamental Algorithm - Linear Regression](/notes/linear-reg.ipynb)
   - [Fundamental Algorithm - Logistic Regression](/notes/logistic-reg.ipynb)

3. **Learning from data**
   - [Learning from data](/notes/learning-from-data.ipynb)
   - [Gradient Descent](/notes/gradient-descent.ipynb)
   - [Stochastic Gradient Descent](/notes/sgd.ipynb)

3. **Neural Networks**
   - [Introduction to Neural Networks](/notes/nn-intro.ipynb)
   - [Types of Neural Networks](/notes/nn-types.ipynb)
   - [Neural Networks Part 1 - Forward Pass & Backpropagation (MicroGrad)](/notes/nn-forward-backprop.ipynb)
   - [Neural Networks Part 2 - Training (MicroGrad)](/notes/nn-training.ipynb)
   - [Neural Networks Part 3 - PyTorch](/notes/nn-pytorch.ipynb)

4. **Dense Neural Networks**

5. **Classification with Neural Networks**

6. **Recurrent Neural Networks**

7. **Optimization and Regularization**

8. **Vector Embeddings**

9. **Working with Text (basics of GPT)**

10. **Transformers**

11. **Building GPT-2**

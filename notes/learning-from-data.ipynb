{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from data\n",
    "\n",
    "In machine learning, we typically create models that predict or classify input values.\n",
    "\n",
    "To get an intution about a model, imagine that it is like an equation.  \n",
    "\n",
    "We are all familar with simple equations like \n",
    "\n",
    "$$\n",
    "y = 2x + 3\n",
    "$$\n",
    "\n",
    "This represents a simple, linear relationship between x and y. For any value $x \\in R$, it is quite easy to determine the value of y.\n",
    "\n",
    "In other words, this model predicts the value of y, given any $x \\in R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, we usually work with lots of data. For example, we might collect data on the square footage of homes and their selling prices. In this case, x is the square footage, and y is the price of the home.\n",
    "\n",
    "Sometimes the relationship between x and y is more complex. For example, it might follow a curve like:\n",
    "\n",
    "$$ y = wx^2 + b $$\n",
    "\n",
    "This is a quadratic equation, which means y depends on the square of x.  (_Note: Remember that a quadratic equation is simply whan the relationship between $x$ and $y$ involes squared terms_)\n",
    "\n",
    "In more complicated cases, we might use multiple inputs. For instance, we could also include the year the home was built. These multiple inputs are typically called _features_ in machine learning (think features of a home). The equation might look like:\n",
    "\n",
    "$$ y = w_1x_1^2 + w_2x_2 + b $$\n",
    "\n",
    "Here, $x_1$ represents the square footage, and $x_2$ represents the year built. \n",
    "\n",
    "In this case, the relationship between ($x_1$, $x_2$) and $y$ are a more complex, like plotting points on a 3D graph\n",
    "\n",
    "These features are often put together into a feature vector:\n",
    "\n",
    "$$ V = [x_1, x_2] $$\n",
    "\n",
    "A feature vector is just a list of numbers representing the different signals or measurements we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Formalizing the Idea\n",
    "\n",
    "Lets put this together a bit more formally\n",
    "\n",
    "Imagine we want to predict something, like the prices of a home based on a square footage of the home. The square footage is our signal $x$, and the prices of the home is our output $y$.\n",
    "\n",
    "In many real-world situations, especially with high-dimensional data (like images), it’s hard to come up with a simple formula that directly relates $x$ to $y$.\n",
    "\n",
    "Instead, we collect a large set of examples, called the training set. This training set contains pairs $(x_n, y_n)$, where $x_n$ is the input and $y_n$ is the _correct_ output.\n",
    "\n",
    "We then create a model, which is a function $f$ with parameters $w$. These parameters are numbers that the model can adjust to improve its predictions.\n",
    "\n",
    "For example, let’s say our function $f$ is predicting the price of a home based on its square footage:\n",
    "\n",
    "$$ f(x; w) = w \\cdot x $$\n",
    "\n",
    "Here, $f(x; w)$ represents the predicted price of a home based on the input $x$  (the square footage). The parameter $w$  is the model’s weight, which determines how much the square footage influences the price prediction. The key point to note ther is that if we adjust $w$, the model changes its predictions.  As we will see later, when we speak about training the model, we are simply referring to finding the best value of $w$\n",
    "\n",
    "If  $w = 300$ , then for a home of 1000 square feet, the predicted price would be:\n",
    "\n",
    "$$ f(1000; 300) = 300 \\cdot 1000 = 300,000 $$\n",
    "\n",
    "So in this case, the model predicts that a 1000-square-foot home will sell for $300,000.\n",
    "\n",
    "Training the model means finding the best values for w so that the model’s predictions are as close as possible to the actual outputs in the training set.\n",
    "\n",
    "We measure how well the model is doing using a loss function, written as $L(w)$. The loss function is small when the model’s predictions are good, and our goal is to find w that makes the loss as small as possible.\n",
    "\n",
    "For example, if we use the mean squared error (MSE) as the loss function, it works like this:\n",
    "\n",
    "Let’s say we have a few data points of actual home prices and their square footage:\n",
    "\n",
    "  - $x_1 = 1000$  sq ft, actual price  $y_1 = 300,000$\n",
    "  - $x_2 = 2000$  sq ft, actual price  $y_2 = 500,000$\n",
    "\n",
    "Our model predicts prices using  $f(x; w) = w \\cdot x$ , and let’s say for now,  $w = 250$. Then, the model’s predictions would be:\n",
    "\n",
    "  - Predicted price for  $x_1$  (1000 sq ft) is  $f(1000; 250) = 250 \\cdot 1000 = 250,000$\n",
    "  - Predicted price for  $x_2$  (2000 sq ft) is  $f(2000; 250) = 250 \\cdot 2000 = 500,000$\n",
    "\n",
    "Now, we can calculate the mean squared error (MSE) to see how far off the predictions are:\n",
    "\n",
    "$$ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - f(x_i; w))^2 $$\n",
    "\n",
    "In this case:\n",
    "\n",
    "$$ MSE = \\frac{1}{2} \\left[ (300,000 - 250,000)^2 + (500,000 - 500,000)^2 \\right] $$\n",
    "\n",
    "$$ MSE = \\frac{1}{2} \\left[ 50,000^2 + 0^2 \\right] = \\frac{1}{2} \\left[ 2.5 \\times 10^9 \\right] = 1.25 \\times 10^9 $$\n",
    "\n",
    "So, the mean squared error here is 1.25 billion. If we adjust  w  to a better value, we can reduce this error and improve the model’s predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
